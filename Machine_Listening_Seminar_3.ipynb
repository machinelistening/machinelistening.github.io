{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Listening - Seminar 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YWIrvyLHyRO"
      },
      "source": [
        "# **Before you start**\n",
        "\n",
        "*   Go to \"*File*\" --> \"*Save a copy in Drive*\"\n",
        "*   Open that copy (might open automatically)\n",
        "*   Then continue below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxWI1Qu9LU6B"
      },
      "source": [
        "---\n",
        "\n",
        "# AST MIR-Seminar 3: Sound classification with simple Neural Networks\n",
        "\n",
        "What we are going to do:\n",
        "* Revisit previous seminar:\n",
        " * Curate a small \"ESC-5\" dataset from the ESC-50 dataset\n",
        " * Create a train and test set\n",
        " * Extract features (mel spectrogram) and cater for labels\n",
        " * Use scikit-learn to classify the test set with a nearest neighbor algorithm\n",
        " * Plot a confusion matrix\n",
        "* First look at creating simple neural networks\n",
        " * Keras / Tensorflow\n",
        " * Dense layers\n",
        " * Activations and Dropout\n",
        " * Fitting and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8HqZlPrMSJJ"
      },
      "source": [
        "---\n",
        "\n",
        "# 1. Fetch the Dataset\n",
        "\n",
        "*   We use ESC-50, a dataset for Environmental Sound Classification (https://github.com/karolpiczak/ESC-50)\n",
        "*   Properties:\n",
        " * 50 classes\n",
        " * 40 files per class\n",
        " * each audio file has a length of 10s\n",
        "*   ***Tasks:***\n",
        " * Download, then\n",
        " * unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_LdsGgAJQIj"
      },
      "source": [
        "!wget https://github.com/karoldvl/ESC-50/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33v35BcrMuv_"
      },
      "source": [
        "!unzip master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6P-n2BpAHwm"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. Import libraries\n",
        "\n",
        "* We will need a number of libraries. So we import them once and use them throughout the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5I12VERAHTc"
      },
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "### Tensorflow check\n",
        "all_devices = tf.config.list_physical_devices()\n",
        "print('Found {} devices: {}'.format( len(all_devices), all_devices ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7drt4EEy4Pf5"
      },
      "source": [
        "Expected output:\r\n",
        "```\r\n",
        "Found 1 devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ThbdIZpytA"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. Curate an ESC-5\n",
        "\n",
        "***Tasks:***\n",
        "* a) We choose 5 classes for our ESC-5 (*our_classes*). Find all files that belong to them. Put the files and their classes in separate lists, but make sure their indices are equal (meaning: the value at index 3 of list *a* is related to the value at index 3 of list *b*).\n",
        " * Idea: Use *df.values* to iterate over the rows of the csv.\n",
        "\n",
        "* b) Print the first 5 elements of each list as (file, class)-tuples. Also, print the overall lengths of the lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WagedjwwqKbA"
      },
      "source": [
        "our_classes = ['crying_baby', 'dog', 'rain', 'rooster', 'sneezing']  # Note: This is also our class map for later.\n",
        "esc5_X = []  # File list\n",
        "esc5_y = []  # Class list\n",
        "fn_csv = 'ESC-50-master/meta/esc50.csv'  # Have a look at the metadata\n",
        "\n",
        "\n",
        "### START CODING ###\n",
        "df = ...  # pandas dataframe df\n",
        "\n",
        "for row in ...:\n",
        "  ...:\n",
        "    esc5_X.append( ... )  # filename column\n",
        "    esc5_y ...  # class column\n",
        "\n",
        " ... zip(esc5_X[:5], esc5_y[:5])\n",
        "print(...)\n",
        "### END CODING ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGAWVpdREruJ"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "[('1-100032-A-0.wav', 'dog'), ('1-110389-A-0.wav', 'dog'), ('1-17367-A-10.wav', 'rain'), ('1-187207-A-20.wav', 'crying_baby'), ('1-211527-A-20.wav', 'crying_baby')]\n",
        "Lengths: esc5_X: 200, esc5_y: 200\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLqQ8AEqLtxm"
      },
      "source": [
        "---\n",
        "\n",
        "# 4. Splitting the dataset into *train* and *test* subsets\n",
        "\n",
        "***Tasks:***\n",
        "* ESC-5 is almost ready. Using sklearn, split the dataset into *train* and *test* subsets with a split ratio of 80%/20% and a random state of 1337.\n",
        "* Print the first 3 elements of the resulting *X_train*.\n",
        "* Print the overall lengths of the resulting lists. Are they aligned with the ratio?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXwi6DjKMe2t"
      },
      "source": [
        "### START CODING HERE ###\n",
        "X_train, X_test, y_train, y_test = train_...\n",
        "\n",
        "...\n",
        "...\n",
        "### END CODING ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWDews_4N53Z"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "['5-203128-A-0.wav', '4-181286-A-10.wav', '3-157615-A-10.wav']\n",
        "X: 160, 40; y: 160, 40\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0avQt2F_Dlv"
      },
      "source": [
        "---\n",
        "# 5. Create mel spectrograms\n",
        "\n",
        "We now have a train set and a test set. They consist of file lists and their respective classes.\n",
        "\n",
        "We need to compute features and corresponding labels for each file in our ESC-5.\n",
        "\n",
        "***Tasks:***\n",
        "* Define a function that does the following (in this order!):\n",
        "  * input parameters: an *X*-list, a *y*-list, and *our_classes*\n",
        "  * loops over the *X*-list (hint: *enumerate* it), and loads each file (.wav) using librosa\n",
        "  * creates the mel spectrogram from the wave data\n",
        "  * normalizes each mel spec by dividing it through the number of mel bands.\n",
        "  * transposes the mel spec\n",
        "  * appends the mel spec features to a large list\n",
        "  * creates a target vector consisting of as many values as there are frames \n",
        "    * hint: use .shape to see which value you need\n",
        "  * each value inside the vector must correspond to the index of the class in *our_classes*\n",
        "    * hint: remember *numpy.ones(...)* ?\n",
        "    * hint: use *.index(...)* here. Not the best idea, but works here.\n",
        "  * appends the targets to a large list\n",
        "  * stacks the large feature and target lists appropriately\n",
        "  * returns the lists\n",
        "* Finally, print the shapes of all 4 arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFU8xzcn_DEQ"
      },
      "source": [
        "### START CODING HERE ###\n",
        "def ...(data_X, data_y):\n",
        "  X = []  # feature tensor\n",
        "  y = []  # target tensor\n",
        "\n",
        "  mel_bands = 128\n",
        "  for i, filename in tqdm(enumerate(data_X)):\n",
        "    wav_data, sr = librosa...  # uses and returns the file's sr, will be used for the mel_spec\n",
        "\n",
        "    # Features\n",
        "    mel_spec = ...  # Create mel spectrogram. Output shape: (128, 216) (n_mels, frames)\n",
        "    mel_spec = ...  # Normalization\n",
        "    mel_spec = ...  # Transposition. Output shape: (216, 128)\n",
        "    mel_spec = mel_spec.astype(np.float16)  # Reduce complexity, saves memory (float64/64bit -> 16bit)\n",
        "    ...  # Append to feature tensor\n",
        "\n",
        "    # Targets == class_name\n",
        "    targets = np.ones( ... )  # Create placeholder target vector. Output shape: (216) (Note: silent frames are not going to be labeled as \"silent\")\n",
        "    targets = targets * ... ( data_y[...] )  # Convert placeholders with actual class-index (our_classes)\n",
        "    ...  # Append to target tensor\n",
        "\n",
        "  # Stack tensors\n",
        "  X = np.vstack(X)\n",
        "  y = np.hstack(y)\n",
        "\n",
        "  return ..., ...\n",
        "\n",
        "\n",
        "# Call the function on our data lists\n",
        "X_train_ready, y_train_ready = ...(X_train, y_train)\n",
        "X_test_ready, y_test_ready = ...\n",
        "### END CODING HERE ###\n",
        "\n",
        "\n",
        "print('\\nShapes: X_train_ready: {}, y_train_ready: {}'.format(X_train_ready.shape, y_train_ready.shape))\n",
        "print('Shapes: X_test_ready: {}, y_test_ready: {}'.format(X_test_ready.shape, y_test_ready.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjknFNijWkEs"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Shapes: X_train_ready: (34560, 128), y_train_ready: (34560,)\n",
        "Shapes: X_test_ready: (8640, 128), y_test_ready: (8640,)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTpKcZ_yR6u9"
      },
      "source": [
        "---\n",
        "\n",
        "# 6. Train a nearest neighbor classifier\n",
        "\n",
        "***Tasks:***\n",
        "* Use the features and targets from above to train (*fit*) a kNN-classifier from scikit-learn, with 5 neighbors and uniform weighting.\n",
        "* Print the scores on the train set and test set, rounded to 4 decimals. (This will take some time!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJRU5UH0SLWi"
      },
      "source": [
        "# Feature scaling\n",
        "print('Scaling...')\n",
        "scaler = StandardScaler()  # zero mean, unit variance normalization (ZMUV)\n",
        "scaler.fit(X_train_ready)\n",
        "X_train_ready = scaler.transform(X_train_ready)\n",
        "X_test_ready = scaler.transform(X_test_ready)\n",
        "\n",
        "\n",
        "### START CODING HERE ###\n",
        "print('Fitting...')\n",
        "model = ...  # Call the kNN classifier. Look at your imports again for a hint.\n",
        "model...  # Fit/Train the classifier using our generated tensors.\n",
        "\n",
        "print('Evaluating...')\n",
        "print('Train score: {}'.format( np.round(model...\n",
        "...\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo1AxUmnVmw5"
      },
      "source": [
        "Expected output (might differ slightly):\n",
        "```\n",
        "Train score: 0.694\n",
        "Test score: 0.5138\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLx_7lpGTYTE"
      },
      "source": [
        "---\n",
        "\n",
        "# 7. Plot the confusion matrix\n",
        "***Tasks:***\n",
        "* Using scikit-learn, create a confusion matrix of our classifier over the test set\n",
        "* Normalize the rows, use our_classes as tick values\n",
        "* Display the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rv6AEPATbo1"
      },
      "source": [
        "### START CODING HERE ###\n",
        "plot_...\n",
        "plt.xticks(ticks=np.arange(5)...)\n",
        "plt.y...\n",
        "plt....\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWpXiWvQZoXK"
      },
      "source": [
        "Expected output:\r\n",
        "\r\n",
        "```\r\n",
        "(a coloured confusion matrix with an emphasis right in the center)\r\n",
        "(each row should add up to 1)\r\n",
        "(labels from our_classes on x-axis and y-axis)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD3wY8AY4aIA"
      },
      "source": [
        "---\n",
        "\n",
        "# **Getting to know Keras for Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MVym7rGapQx"
      },
      "source": [
        "# https://machinelearningmastery.com/keras-functional-api-deep-learning/\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdLJ9_FsZQrf"
      },
      "source": [
        "# One-hot encoding (OHE) of targets (binary class matrix)\n",
        "\n",
        "With 5 classes, we have a multi-class problem. So, we will 'categorize' our targets. A target with index '3' becomes OHE'd: [0 0 0 1 0]\n",
        "(https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZAUZhaJaDCR"
      },
      "source": [
        "# Shapes so far\n",
        "print('y_train_ready.shape: {}, y_test_ready.shape: {}'.format( y_train_ready.shape, y_test_ready.shape ))\n",
        "\n",
        "# Now we OHE\n",
        "### START CODING HERE ###\n",
        "y_train_ready_OHE = to_categorical(y=y_train_ready, num_classes=...)  # How many classes do we have again?\n",
        "... # Do the same for the test set\n",
        "\n",
        "# New shapes\n",
        "print(...)\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOalad4qHio0"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "y_train_ready.shape: (34560,), y_test_ready.shape: (8640,)\n",
        "y_train_ready_OHE.shape: (34560, 5), y_test_ready_OHE.shape: (8640, 5)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8bkG9kdagcq"
      },
      "source": [
        "# Building a simple DNN (Sequential API & Functional API)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YehtNLdHMs7Y"
      },
      "source": [
        "* Building an NN can be straightforward. We use a very simple and extendable \n",
        "architecture.\n",
        "* Training and evaluating a NN is very similar to what you saw in the kNN-classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bErXfZa04dgw"
      },
      "source": [
        "# Using the Sequential API\r\n",
        "model_s = Sequential()\r\n",
        "model_s.add(Dense(128, input_dim=128))       # input layer, 128 input features due to our feature extraction process (Dense == Fully Connected)\r\n",
        "model_s.add(Dense(256, activation='relu'))   # hidden layer 1\r\n",
        "model_s.add(Dense(64, activation='relu'))    # hidden layer 2\r\n",
        "model_s.add(Dense(5, activation='sigmoid'))  # output layer. Most of the time, this is sigmoid (each index can be between 0 and 1), or softmax (all indices sum up to 1)\r\n",
        "\r\n",
        "# Using the Functional API\r\n",
        "model_f_in = Input(shape=(128,))                         # input layer\r\n",
        "model_f_x = Dense(10, activation='relu')(model_f_in)     # hidden layer 1\r\n",
        "model_f_x = Dense(10, activation='relu')(model_f_x)      # hidden layer 2\r\n",
        "model_f_x = Dense(10, activation='relu')(model_f_x)      # hidden layer 3\r\n",
        "model_f_out = Dense(5, activation='sigmoid')(model_f_x)  # output layer\r\n",
        "model_f = Model(inputs=model_f_in, outputs=model_f_out)  # model instance, specified with input and output layers\r\n",
        "\r\n",
        "# We use model_f in the following\r\n",
        "model = model_f\r\n",
        "\r\n",
        "# Compile the model and show a summary of it\r\n",
        "model.compile(optimizer=SGD(lr=0.001), loss=CategoricalCrossentropy(), metrics=['accuracy'])  # Given this loss function, 'accuracy' means 'Categorical Accuracy'. Notice how 'Categorical' relates to OHE\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_b6zHy1NDCf"
      },
      "source": [
        "*   Now we want to train this DNN on the train set with the OHE'd targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew_7hYr9qKo3"
      },
      "source": [
        "model.fit(x=X_train_ready, y=y_train_ready_OHE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZHjOGnyNJMG"
      },
      "source": [
        "Expected output (may differ):\n",
        "```\n",
        "1080/1080 [==============================] - 3s 2ms/step - loss: 1.7089 - accuracy: 0.2835\n",
        "<tensorflow.python.keras.callbacks.History at 0x7f9859532d50>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VVyS1mfNQ5O"
      },
      "source": [
        "* Now it's time to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnai2ir6sMuv"
      },
      "source": [
        "# Predicting over test set\n",
        "predictions = model.predict(X_test_ready)\n",
        "print(predictions.shape)\n",
        "\n",
        "# Evaluating quality of model\n",
        "score = model.evaluate(X_test_ready, y_test_ready_OHE, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NxcQm05sOJi"
      },
      "source": [
        "# Plot confusion matrix\n",
        "confmat = confusion_matrix(y_test_ready_OHE.argmax(axis=1), predictions.argmax(axis=1), normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confmat, display_labels=our_classes)\n",
        "disp.plot(xticks_rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-7u5OjLbykv"
      },
      "source": [
        "# Building a simple CNN (Functional API)\n",
        "\n",
        "* Using the functional API, we are now building a CNN with a few layers.\n",
        "* Feel free to adjust number of filters and kernel sizes. Watch out you don't shrink the output too much by doing so!\n",
        "* In the summary, note what happens with the model after each layer, especially after pooling.\n",
        "\n",
        "**NOTE:** First, have a look at how the model is built.\n",
        "Then, go on to the next cell. Input shapes are explained there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9lPoY59b5Z9"
      },
      "source": [
        "model_cnn_in = Input(shape=(1,128,1))  # We give 3 dims here...? 'num_examples' can be left 'unknown'. Note the (None) in the summary. (Also, see next cell for more info.)\n",
        "model_cnn_conv1 = Conv2D(filters=32, kernel_size=(1, 3), activation='relu')(model_cnn_in)  # Since input is a vector (1, 128), we span the kernel over the feature dimension only\n",
        "model_cnn_pool1 = MaxPooling2D(pool_size=(1, 2))(model_cnn_conv1)  # Same as above: We pool only in frequency dimension\n",
        "model_cnn_conv2 = Conv2D(filters=64, kernel_size=(1, 3), activation='relu')(model_cnn_pool1)\n",
        "model_cnn_pool2 = MaxPooling2D(pool_size=(1, 2))(model_cnn_conv2)\n",
        "model_cnn_conv2 = Conv2D(filters=128, kernel_size=(1, 3), activation='relu')(model_cnn_pool2)\n",
        "model_cnn_flat = Flatten()(model_cnn_conv2)\n",
        "model_cnn_drop1 = Dropout(0.2)(model_cnn_flat)\n",
        "model_cnn_dense1 = Dense(64, activation='relu')(model_cnn_drop1)\n",
        "model_cnn_out = Dense(5, activation='sigmoid')(model_cnn_dense1)\n",
        "model_cnn = Model(inputs=model_cnn_in, outputs=model_cnn_out)\n",
        "\n",
        "model_cnn.compile(optimizer=SGD(lr=0.1), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNKCoRs7Nxlx"
      },
      "source": [
        "**CNN: Preparation of tensors**\n",
        "* For 2D convolutional layers, we need to reshape our tensors.\n",
        "* 2D conv layers take a 4D-input of the form NHWC (*num_examples, height, width, channels*).\n",
        "  * *num_examples*: (in this case) total number of frames (here: 34560 for the train set)\n",
        "  * *height*: number of time frames per example (here: 1)\n",
        "  * *width*: feature dimension (here: 128)\n",
        "  * *channels*: audio is mono, so 1\n",
        "\n",
        "**NOTE:** Above numbers are valid for our frame-based approach.\n",
        "We could also translate *num_examples* into number of files, then each example would have a *height* of 216 (each file has 216 frames)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8hlPjK2N2IR"
      },
      "source": [
        "# Convert tensors to correct input shape (for both training and test sets)\n",
        "print('Shapes: X_train_ready {}, y_train_ready_OHE {}'.format(X_train_ready.shape, y_train_ready_OHE.shape))\n",
        "# X_train_ready (34560, 128)    <-- needs format adjustment\n",
        "# y_train_ready_OHE (34560, 5)  <-- already in correct format\n",
        "\n",
        "\n",
        "### START CODING HERE ###\n",
        "# Add channel dimension\n",
        "X_train_cnn = np.expand_dims(X_train_ready, axis=-1)  # (34560, 128, 1)\n",
        "... # Do the same for the test set\n",
        "\n",
        "# Add height dimension\n",
        "X_train_cnn = np.expand_dims(X_train_cnn, axis=1)  # (34560, 1, 128, 1)\n",
        "... # Do the same for the test set\n",
        "\n",
        "# New shapes\n",
        "print(...)  # Print shapes of the CNN-ready train set and test set \n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUqWuj-UPNXW"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Shapes: X_train_ready (34560, 128), y_train_ready_OHE (34560, 5)\n",
        "Final shapes: X_train_cnn (34560, 1, 128, 1), X_test_cnn (8640, 1, 128, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow4Dm3q5OGdL"
      },
      "source": [
        "# Start fitting\n",
        "model_cnn.fit(x=X_train_cnn, y=y_train_ready_OHE, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvLUjGTNP1d_"
      },
      "source": [
        "Expected output (or similar):\n",
        "```\n",
        "2160/2160 [==============================] - 20s 9ms/step - loss: 0.8811 - accuracy: 0.6036\n",
        "<tensorflow.python.keras.callbacks.History at 0x7ffa6e4c93d0>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jHKAYgtP57Q"
      },
      "source": [
        "# Predicting over test set\n",
        "predictions = model_cnn.predict(X_test_cnn)\n",
        "print(predictions.shape)\n",
        "\n",
        "\n",
        "### START CODING HERE ###\n",
        "# Evaluating quality of model\n",
        "model_cnn....\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWNBfQxFQbWE"
      },
      "source": [
        "Expected output (or similar):\n",
        "```\n",
        "(8640, 5)\n",
        "270/270 [==============================] - 1s 5ms/step - loss: 1.0113 - accuracy: 0.5602\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaUqSUjKQqv7"
      },
      "source": [
        "* For the confusion matrix, we consider the *argmax* again.\n",
        "* This means: We retrieve the actual index of the predicted class and compare it with the actual index of the true class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uobOwbtbP7nX"
      },
      "source": [
        "### START CODING HERE ####\n",
        "# Plot confusion matrix\n",
        "confmat = confusion_matrix(y_test_ready_OHE.argmax(axis=1), predictions.argmax(axis=1), normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=..., display_labels=...)\n",
        "disp.plot(...)  # rotate labels on x-axis for readability\n",
        "...  # display plot\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVK0ak1rR6U4"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "```\n",
        "(a coloured confusion matrix)\n",
        "(each row should add up to 1)\n",
        "(labels from our_classes on x-axis and y-axis)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxKGaZL_P93g"
      },
      "source": [
        "# Hyper-parameter tuning\n",
        "\n",
        "Try playing around with a different\n",
        "\n",
        "* learning rate (go in steps of an order of magnitude, e.g. 0.1, 0.001...)\n",
        "* batch size (e.g. 1, 16, 32, 216. 216 will result in 160 batches. Where have you seen this number before?)\n",
        "\n",
        "and see how it affects the results."
      ]
    }
  ]
}