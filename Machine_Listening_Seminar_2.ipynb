{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Listening - Seminar 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YWIrvyLHyRO"
      },
      "source": [
        "# **Before you start**\n",
        "\n",
        "*   Go to \"*File*\" --> \"*Save a copy in Drive*\"\n",
        "*   Open that copy (might open automatically)\n",
        "*   Then continue below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxWI1Qu9LU6B"
      },
      "source": [
        "---\n",
        "\n",
        "# AST MIR-Seminar 2: Building a simple sound classification system\n",
        "\n",
        "What we are going to do:\n",
        "*   Download a suitable, simple dataset\n",
        "*   Have a look at the metadata (csv)\n",
        "*   Choose a few classes from that dataset\n",
        "*   Find corresponding audio files\n",
        "*   Construct a train and test set\n",
        "*   Extract features (mel spectrogram) and cater for labels\n",
        "*   Use scikit-learn to classify the test set with a nearest neighbor algorithm\n",
        "*   Build a confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8HqZlPrMSJJ"
      },
      "source": [
        "---\n",
        "\n",
        "# 1. Fetch the Dataset\n",
        "\n",
        "*   We use ESC-50, a dataset for Environmental Sound Classification\n",
        "*   Properties:\n",
        " * 50 classes\n",
        " * 40 files per class\n",
        " * each audio file has a length of 10s\n",
        "*   ***Tasks:***\n",
        " * Download, then\n",
        " * unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_LdsGgAJQIj"
      },
      "source": [
        "!wget https://github.com/karoldvl/ESC-50/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33v35BcrMuv_"
      },
      "source": [
        "!unzip master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6P-n2BpAHwm"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. Import libraries\n",
        "\n",
        "* We will need a number of libraries. So we import them once and use them throughout the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5I12VERAHTc"
      },
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef9yVlYcWyX0"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. Metadata check and quick analysis\n",
        "\n",
        "***Tasks:***\n",
        "* Use the pandas module to read the csv file in ESC-50-master/meta/\n",
        "* Print the first elements of the csv (note: Pandas has a standard function for this)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM_bobykZISi"
      },
      "source": [
        "fn_csv = 'ESC-50-master/meta/esc50.csv'\n",
        "\n",
        "\n",
        "### START CODING\n",
        "df = pd...  # pd = pandas dataframe. one-liner to read a csv file\n",
        "...\n",
        "### END CODING"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osdQpR0jbuBQ"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "    filename            fold  target  category        esc10   src_file  take\n",
        "0   1-100032-A-0.wav    1     0       dog             True    100032    A\n",
        "1   1-100038-A-14.wav   1     14      chirping_birds  False   100038    A\n",
        "2   1-100210-A-36.wav   1     36      vacuum_cleaner  False   100210    A\n",
        "3   1-100210-B-36.wav   1     36      vacuum_cleaner  False   100210    B\n",
        "4   1-101296-A-19.wav   1     19      thunderstorm    False   101296    A\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4ThbdIZpytA"
      },
      "source": [
        "---\n",
        "\n",
        "# 4. Curate an own dataset ESC-5\n",
        "\n",
        "***Tasks:***\n",
        "* a) Use the pandas dataframe *df* from above to find the set of all classes in ESC-50. Sort it, then print the first 10.\n",
        "* b) We choose 5 classes for our ESC-5 (see *our_classes* variable). Find all files that belong to them. Put the files and their classes in separate lists, but make sure their indices are equal.\n",
        " * One idea: Use *df.values* to iterate over the rows of the csv.\n",
        "\n",
        "* c) Finally, print the first 5 elements of each list as [file, class]-tuples. Also, print the overall lengths of the lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WagedjwwqKbA"
      },
      "source": [
        "our_classes = ['crying_baby', 'dog', 'rain', 'rooster', 'sneezing']  # Note: This is also our class map for later.\n",
        "esc5_X = []  # File list\n",
        "esc5_y = []  # Class list\n",
        "\n",
        "\n",
        "### START CODING ###\n",
        "# task 4a)\n",
        "all_classes = ...\n",
        "...\n",
        "\n",
        "# task 4b)\n",
        "for ... in df.values:\n",
        "   ...\n",
        "\n",
        "# task 4c)\n",
        "...\n",
        "### END CODING ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGAWVpdREruJ"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "['airplane', 'breathing', 'brushing_teeth', 'can_opening', 'car_horn', 'cat', 'chainsaw', 'chirping_birds', 'church_bells', 'clapping']\n",
        "[('1-100032-A-0.wav', 'dog'), ('1-110389-A-0.wav', 'dog'), ('1-17367-A-10.wav', 'rain'), ('1-187207-A-20.wav', 'crying_baby'), ('1-211527-A-20.wav', 'crying_baby')]\n",
        "Lengths: esc5_X: 200, esc5_y: 200\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLqQ8AEqLtxm"
      },
      "source": [
        "---\n",
        "\n",
        "# 5. Splitting the dataset into *train* and *test* subsets\n",
        "\n",
        "***Tasks:***\n",
        "* ESC-5 is almost ready. Define a suitable split ratio, and use sklearn to do the splitting.\n",
        "* Print the lengths of your resulting lists. Are they aligned with the ratio?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXwi6DjKMe2t"
      },
      "source": [
        "### START CODING HERE ###\n",
        "\n",
        "X_train, X_test, y_train, y_test = ...  # train 80%, test 20%\n",
        "print(...)\n",
        "\n",
        "### END CODING ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWDews_4N53Z"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Lengths: X_train: 160, X_test: 40, y_train: 160, y_test: 40\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0avQt2F_Dlv"
      },
      "source": [
        "---\n",
        "# 6. Create mel spectrograms\n",
        "\n",
        "We need to compute features and corresponding labels for each file in our ESC-5.\n",
        "\n",
        "***Tasks:***\n",
        "* Define a function that does the following (in this order!):\n",
        "  * input parameters: an *X*-list, a *y*-list, and *our_classes*\n",
        "  * loops over the *X*-list (hint: *enumerate* it), and loads each file (.wav) using librosa\n",
        "  * creates the mel spectrogram from the wave data\n",
        "  * normalizes each mel spec by dividing it through the number of mel bands.\n",
        "  * transposes the mel spec\n",
        "  * appends the mel spec features to a large list\n",
        "  * creates a target vector consisting of as many values as there are frames \n",
        "    * hint: use *.shape* to see which value you need\n",
        "  * each value inside the vector must correspond to the index of the class in *our_classes*\n",
        "    * hint: remember *numpy.ones(...)* ?\n",
        "    * hint: use *.index(...)* here. Not the best idea, but works here.\n",
        "  * appends the targets to a large list\n",
        "  * stacks the large feature and target lists appropriately\n",
        "  * returns the lists\n",
        "* Finally, print the shapes of all 4 arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFU8xzcn_DEQ"
      },
      "source": [
        "### START CODING HERE ###\n",
        "def extract_mel_spec(...):\n",
        "  X = []  # feature tensor\n",
        "  y = []  # target tensor\n",
        "\n",
        "  mel_bands = 128\n",
        "  for ... in tqdm(...):\n",
        "    wav_data, sr = ...\n",
        "\n",
        "    mel_spec = ...  # Create mel spectrogram. Output shape: (128, 216) (n_mels, frames)\n",
        "    mel_spec = ...  # Normalization\n",
        "    mel_spec = ...  # Transposition. Output shape: (216, 128)\n",
        "    mel_spec = mel_spec.astype(np.float16)  # Reduce complexity, saves memory (64bit -> 16bit)\n",
        "    ...  # Append to tensor\n",
        "\n",
        "    targets = ...  # Create placeholder target vector. Output shape: (216)\n",
        "    targets = targets * ...  # Convert placeholders with actual class-index\n",
        "    ...  # Append to tensor\n",
        "\n",
        "  # Stack tensors\n",
        "  X = ...\n",
        "  y = ...\n",
        "\n",
        "  return ...\n",
        "\n",
        "\n",
        "# Call the function on our data lists\n",
        "X_train_ready, y_train_ready = extract_mel_spec(...)\n",
        "X_test_ready, y_test_ready = extract_mel_spec(...)\n",
        "\n",
        "print(...)\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjknFNijWkEs"
      },
      "source": [
        "Expected output:\n",
        "```\n",
        "Shapes: X_train_ready: (34560, 128), y_train_ready: (34560,)\n",
        "Shapes: X_test_ready: (8640, 128), y_test_ready: (8640,)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTpKcZ_yR6u9"
      },
      "source": [
        "---\n",
        "\n",
        "# 7. Train a nearest neighbor classifier\n",
        "\n",
        "***Tasks:***\n",
        "* Use the features and targets from above to train (*fit*) a kNN classifier from scikit-learn, with 5 neighbors and uniform weighting.\n",
        "* Print the score on the train set, rounded to 4 decimals.\n",
        "* Print the score on the test set, rounded to 4 decimals.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJRU5UH0SLWi"
      },
      "source": [
        "# Some feature scaling beforehand...\n",
        "scaler = StandardScaler()  # zero mean, unit variance normalization (ZMUV)\n",
        "scaler.fit(X_train_ready)\n",
        "X_train_ready = scaler.transform(X_train_ready)\n",
        "X_test_ready = scaler.transform(X_test_ready)\n",
        "\n",
        "\n",
        "### START CODING HERE ###\n",
        "model = ...  # Call the kNN classifier. Look at your imports on top again for a hint.\n",
        "...  # Fit the classifier using our generated tensors.\n",
        "\n",
        "print(...)\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo1AxUmnVmw5"
      },
      "source": [
        "Expected output (or similar):\n",
        "```\n",
        "Train score: 0.7735\n",
        "Test score: 0.4802\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLx_7lpGTYTE"
      },
      "source": [
        "---\n",
        "\n",
        "# 8. Plot the confusion matrix\n",
        "* Use scikit-learn to create a confusion matrix over the test set (one line of code)\n",
        "* Make sure to normalize the rows\n",
        "* Plot it\n",
        "* For reference, print out *our_classes* once more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rv6AEPATbo1"
      },
      "source": [
        "### START CODING HERE ###\n",
        "plot_confusion_matrix(...)\n",
        "...\n",
        "print(...)\n",
        "### END CODING HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8X_HRER1iXp"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "```\n",
        "-> a coloured confusion matrix here <-\n",
        "\n",
        "['crying_baby', 'dog', 'rain', 'rooster', 'sneezing']\n",
        "```\n",
        "\n"
      ]
    }
  ]
}