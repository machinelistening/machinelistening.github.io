{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4218b705",
   "metadata": {},
   "source": [
    "# AI-based Audio Analysis of Music and Soundscapes\n",
    "\n",
    "## Audio Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690b683",
   "metadata": {},
   "source": [
    "## <font color='red'>Programming Session #1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c119f",
   "metadata": {},
   "source": [
    "This notebook provides concrete examples on how to process audio files for later sound classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1612f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as pl\n",
    "import platform\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bff157",
   "metadata": {},
   "source": [
    "### *(Platform-independent Code)*\n",
    "\n",
    "**HINT**: if you want to write Python scripts that work on multiple platforms (like Windows, Linux etc.), you can use ```platform.platform()``` to figure out automatically, which platform your Python code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current platform\n",
    "print(platform.platform())\n",
    "\n",
    "# use if/else conditions\n",
    "if \"Windows\" in platform.platform():\n",
    "    dir_audio = 'C:/audio_files'\n",
    "else:\n",
    "    dir_audio = '/my_server/audio_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200a9a7",
   "metadata": {},
   "source": [
    "### Load audio files\n",
    "\n",
    "This script loads 2 audio files that we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba88fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "if not os.path.isfile('piano.wav') or not os.path.isfile('bird.wav'):\n",
    "    for fn in ('piano.wav', 'bird.wav'):\n",
    "        wget.download('https://github.com/machinelistening/machinelistening.github.io/blob/master/{}?raw=true'.format(fn), \n",
    "                      out=fn, bar=None)\n",
    "else:\n",
    "    print('Files already exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90472a8",
   "metadata": {},
   "source": [
    "### File paths\n",
    "\n",
    "When working with multiple audio files, it is a good practice to treat directories and filenames separately and use ```os.path.join``` to combine both to absolute filenames. This command uses the correct delimiter signs for all operating systems (Windows, MacOS, Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) define path to the directory that contains the audio files (WAV format)\n",
    "# TIP: under Windows, it is also recommended to use '/', e.g. 'C:/my_audio_files'\n",
    "dir_wav = ''  # here, we use the same directory as the notebook is in\n",
    "\n",
    "# this could also look like\n",
    "# dir_wav = 'c:/audio_files'\n",
    "\n",
    "# 2) create absolute path of audio file (directory + filename)\n",
    "# os.path.join takes care of the correct delimiter signs\n",
    "# - Linux / MacOSx: \"/\"\n",
    "# - Windows: \"\\\\\"\n",
    "\n",
    "fn_wav = os.path.join(dir_wav, 'bird.wav')  # original filename: 416529__inspectorj__bird-whistling-single-robin-a_2s\n",
    "print(fn_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c841a33",
   "metadata": {},
   "source": [
    "### Loading audio files\n",
    "\n",
    "- first check librosa documentation: https://librosa.org/doc/main/generated/librosa.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61060c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) use the sample rate of the file, load stereo if needed\n",
    "x, fs = librosa.load(fn_wav)\n",
    "\n",
    "print(\"Sample vector shape:\", x.shape)  # 1D numpy array, mono\n",
    "print(\"Sample rate [Hz]\", fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) you could also enforce another sample rate\n",
    "fs_fix = 44100\n",
    "x, fs = librosa.load(fn_wav, sr=fs_fix)  # in this case, the signal is upsampled to a higher sample rate\n",
    "\n",
    "print(x.shape)  # ! increase of sampling rate (upsampling) -> more samples!\n",
    "print(fs) # ! fix sample rate was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) if you have a stereo file, you can enforce one channel audio (mono)\n",
    "# x, fs = librosa.load(fn_wav, mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687a7f6",
   "metadata": {},
   "source": [
    "### Sonification\n",
    "\n",
    "Let's listen to our example audio file (birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d871d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c2179",
   "metadata": {},
   "source": [
    "### Plot waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55738558",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(x)\n",
    "pl.show()  # ! observe that the x-axis just shows the sample number so far, this is not informative without the sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96e6e8",
   "metadata": {},
   "source": [
    "#### Create time axis\n",
    "\n",
    "The sample rate in Hz defines, how many audio samples exist per second. If we compute the inverse ($1/f_\\mathrm{s}$), we get the duration of each sample in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6054e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(x)\n",
    "print(\"Number of samples:\", number_of_samples)\n",
    "seconds_per_sample = 1/fs\n",
    "print(\"Duration [seconds] of one sample\", seconds_per_sample)  # on audio sample corresponds to ~22.7 ms\n",
    "# let's create a numpy array with the physical time of each audio sample\n",
    "frames_in_seconds = np.arange(number_of_samples)*seconds_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the signal again, this time with an interpretable x-axis\n",
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(frames_in_seconds, x)\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Amplitude')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221ec20",
   "metadata": {},
   "source": [
    "### Spectrogram using Short-Time Fourier Transform (STFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb56dd4",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.stft.html?highlight=stft#librosa-stft\n",
    "\n",
    "The most important parameters are \n",
    "  - **win_length** - this is the size of our analysis window (in samples)\n",
    "  - **hop_length** - this is the hop size of our analysis window (in samples), usually this is chosen to be half the window size\n",
    "  - (**n_fft**) - this is the used \"FFT size\", which can be bigger than the **win_length** (but should be a power of two, such that the Fast Fourier Transform (FFT) algorithm can be used internally)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the STFT\n",
    "n_fft = 2048\n",
    "hop_length = 1024\n",
    "X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)  # using the default values: n_fft=2048, \n",
    "print(\"Shape of STFT:\", X.shape)  # we get n_fft//2 - 1 bins, the reason is that the STFT has a \n",
    "                                  # symmetric structure and we can discard several entries\n",
    "print(\"Data type of STFT:\", X.dtype)  # ! the STFT is complex and has a magnitude and a phase\n",
    "\n",
    "# We'll focus on the magnitude of the STFT\n",
    "S = np.abs(X)\n",
    "print(\"Shape of the magnitude spectrogram:\", S.shape)\n",
    "print(\"Data type of the magnitude spectrogram:\", S.dtype)  # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec718b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it\n",
    "pl.figure(figsize=(6,4))\n",
    "pl.imshow(S, aspect=\"auto\")\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe1f25",
   "metadata": {},
   "source": [
    "There a several **problems** with this plot:\n",
    "  1. the frequency axis is flipped (lower frequencies are shown on top and higher frequencies are shown at the bottom)\n",
    "  2. only the loudest frequency components are visible  \n",
    "  3. we want the axes to show the frequency in Hz (y-axis) and the time in seconds (x-axis), at the moment, we only see the frequency bin (y-axis) of the STFT and the frame number (x-axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 1.) use \"origin\" parameter for imshow()\n",
    "pl.figure(figsize=(6,4))\n",
    "pl.imshow(S, aspect=\"auto\", origin=\"lower\")\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19652f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 2.) apply logarithmic compression to the magnitude values -> this converts the linear magnitudes to decibels (dB)\n",
    "S_dB = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea123e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(6,4))\n",
    "pl.imshow(S_dB, aspect=\"auto\", origin=\"lower\")\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2328b9",
   "metadata": {},
   "source": [
    "We observe that\n",
    "1.  also parts with lower magnitudes are now better visible\n",
    "2.  the value range shifts from [0, 70] to [-80, 0], this is because of the logarithmic compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 3.) define maximum frequency, and maximum time value\n",
    "f_max = fs/2\n",
    "t_max = number_of_samples / fs\n",
    "print(f_max)\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95451470",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(6,4))\n",
    "# use \"extent\" parameter to define actual range of values along x / y acis\n",
    "pl.imshow(S_dB, aspect=\"auto\", origin=\"lower\", extent=[0, t_max, 0, f_max])\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Frequency [Hz]')\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a80ce",
   "metadata": {},
   "source": [
    "## <font color='red'>Programming Session #2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e58c8",
   "metadata": {},
   "source": [
    "### Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5837ae",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **n_mels** - number of Mel frequency bands (commonly: 64 or 128)\n",
    "  - **win_length** - see above (STFT)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **n_fft** - see above (STFT)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = librosa.feature.melspectrogram(y=x, n_fft=2048, hop_length=1024, n_mels=128, fmax=fs/2)  \n",
    "print(\"Shape of Mel spectrogram:\", M.shape)  # frequency x time: we get n_mels frequency bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8fba0",
   "metadata": {},
   "source": [
    "Let's visualize it. We want to\n",
    "1. convert the time axis (horizontal axis) to seconds (as done before for the STFT)\n",
    "2. have physical frequency values [Hz] at the vertical axis, that correspond to the 128 mel bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dB compression as before\n",
    "M_dB = librosa.amplitude_to_db(M, ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f9483",
   "metadata": {},
   "source": [
    "Now, we use the build-in visualization function ```specshow``` of librosa, which allows to visualize STFT spectrograms, Mel spectrograms, and others.\n",
    "\n",
    "Check the documentation for more info: https://librosa.org/doc/main/generated/librosa.display.specshow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots()\n",
    "# note the keyword \"mel\", which indicates that a mel frequency axis is used\n",
    "img = librosa.display.specshow(M_dB, x_axis='time', y_axis='mel', sr=fs, ax=ax, fmax=fs/2, cmap='viridis')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12b15f",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25910d94",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.cqt.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **n_fft** - see above (STFT)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **n_mfcc** - Number of MFC coefficients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute and visualize 13 MFCCs\n",
    "n_mfcc = 20\n",
    "mf = librosa.feature.mfcc(y=x, sr=fs, S=None, n_mfcc=n_mfcc, dct_type=2, norm='ortho', lifter=0, n_fft=n_fft, hop_length=hop_length)\n",
    "pl.figure()\n",
    "pl.imshow(mf, aspect=\"auto\", origin=\"lower\", extent=[0, t_max, 0, mf.shape[0]])\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('MFCC')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4aef2b",
   "metadata": {},
   "source": [
    "### Constant-Q Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2f572",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.cqt.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **f_min** - minimum frequency (we can use the default value of 32.70 Hz which corresponds to the note C1)\n",
    "  - **n_bins** - total number of frequency bins (e.g., for a frequency resolution of one bin per semitone and 4 octaves, this would be 4 * 12 = 48)\n",
    "  - **bins_per_octave** - Logarithmic frequency resolution (frequency bins per octave, commonly: 12 or 36)\n",
    "  - **tuning** - Tuning offset (can be used if known tuning frequency of an audio recording deviates from 440 Hz) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b1455",
   "metadata": {},
   "source": [
    "We'll now use a short piano recording as running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = os.path.join(dir_wav, 'piano.wav')  # original filename: 196765__xserra__piano-phrase.wav\n",
    "x, fs = librosa.load(fn_wav)\n",
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d77c29",
   "metadata": {},
   "source": [
    "Let's compute the CQT for a frequency range of 5 octaves with a resolution of 1 bin per semitone (=12 bins per octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_octaves = 5  # let's capture 5 octaves starting from C1\n",
    "bins_per_octave = 12  # let's choose a frequency resolution of 100 cent (= one frequency bin per semitone)\n",
    "C = np.abs(librosa.cqt(x, sr=fs, n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "print(\"Shape of CQT:\", C.shape)  # logically, we get 60 frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dB magnitude scaling\n",
    "C = librosa.amplitude_to_db(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cadeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use again the visualization tool provided by librosa\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe732d1",
   "metadata": {},
   "source": [
    "We can observe that \n",
    "- the time resolution improves for higher frequencies (see lecture)\n",
    "- for all pitches, we observe a similar energy pattern along the frequency axis (just shifted vertically according to the pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04797930",
   "metadata": {},
   "source": [
    "Now let's do the same for a finer frequency resolution (5 bins per semitone, 60 bins per octave). This will give us finer spectral peaks for the fundamental frequency and the partial frequencies.\n",
    "\n",
    "If you analyze audio recordings with fundamental frequency modulations (such as vibrato in singing recordings), it's always recommended to use higher frequency resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da62297",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_per_octave = 50\n",
    "C = np.abs(librosa.cqt(x, sr=fs, n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "print(\"Shape of CQT:\", C.shape)\n",
    "C = librosa.amplitude_to_db(C)\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57e4c1",
   "metadata": {},
   "source": [
    "### CENS (Chroma Energy Normalize) Chroma Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e4532",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.feature.chroma_cens.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **f_min** - minimum frequency (we can use the default value of 32.70 Hz which corresponds to the note C1)\n",
    "  - **n_bins** - total number of frequency bins (e.g., for a frequency resolution of one bin per semitone and 4 octaves, this would be 4 * 12 = 48)\n",
    "  - **bins_per_octave** - Logarithmic frequency resolution (frequency bins per octave, commonly: 12 or 36)\n",
    "  - **tuning** - Tuning offset (can be used if known tuning frequency of an audio recording deviates from 440 Hz) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a78ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length=128\n",
    "cens = librosa.feature.chroma_cens(y=x, sr=fs, hop_length=hop_length, fmin=None, tuning=None, n_chroma=12, n_octaves=7, bins_per_octave=36)\n",
    "t_max = len(x) / fs\n",
    "\n",
    "pl.figure()\n",
    "pl.imshow(cens, aspect=\"auto\", interpolation=\"None\", origin=\"lower\", extent=[0, t_max, 0, cens.shape[0]])\n",
    "# let's create an interpretable pitch axis\n",
    "pl.yticks([0.5, 2.5, 4.5, 5.5, 7.5, 9.5, 11.5], ['C', 'D', 'E', 'F', 'G', 'A', 'B'])\n",
    "pl.xlabel('Time (seconds)')\n",
    "pl.ylabel('Pitch Class')\n",
    "pl.title('CENS')\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679f9fc",
   "metadata": {},
   "source": [
    "The chroma features give a nice visual summary of the pitch class distribution over time. \n",
    "\n",
    "**Note**: this is not a transcription as the pitch classes of the partial frequencies also affect this representation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94923f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
